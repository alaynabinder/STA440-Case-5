---
title: "Analysis"
output: pdf_document
---

```{r}
library(tidyverse)
```

```{r}
load("strokeStudy.RData")
```


```{r}
x$siteID <- as.character(x$siteID)
unique(x$siteID)

```


# EDA (MISSINGNESS)

```{r}
#| label: missingness-by-outcome

# Remove NAs from outcome
x <- x |>
  filter(!is.na(homeOrRehab))

missing_vars <- c("Age", "PreHospNotify", "EMSvsCar")

x_missing_outcome <- x |>
  mutate(
    homeOrRehab = factor(homeOrRehab),
    across(all_of(missing_vars), as.character)
  ) |>
  pivot_longer(
    cols = all_of(missing_vars),
    names_to = "variable",
    values_to = "value"
  ) |>
  mutate(is_missing = is.na(value)) |>
  group_by(variable, homeOrRehab) |>
  summarize(prop_missing = mean(is_missing), .groups = "drop")

ggplot(x_missing_outcome,
       aes(x = homeOrRehab, y = prop_missing, fill = homeOrRehab)) +
  geom_col() +
  facet_wrap(~ variable) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    title = "Missingness by Outcome",
    x = "Outcome",
    y = "Percent Missing"
  ) +
  theme_minimal() +
  theme(legend.position = "none")
```

```{r}
#| label: missingness-by-site-and-time

missing_by_site_time <- x |>
  select(siteID, Time2, all_of(missing_vars)) |>
  mutate(across(all_of(missing_vars), as.character)) |>
  pivot_longer(
    cols = all_of(missing_vars),
    names_to = "variable",
    values_to = "value"
  ) |>
  mutate(is_missing = is.na(value)) |>
  group_by(siteID, Time2, variable) |>
  summarize(prop_missing = mean(is_missing), .groups = "drop")

ggplot(missing_by_site_time,
       aes(x = Time2, y = siteID, fill = prop_missing)) +
  geom_tile() +
  facet_wrap(~ variable, nrow = 2) +
  scale_fill_continuous(labels = scales::percent_format()) +
  labs(
    title = "Missingness by Site and Time",
    x = "Study Quarter",
    y = "Site",
    fill = "Percent Missing"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 8),
    strip.text = element_text(size = 12)
  )

library(mice)
md.pattern(x,rotate.names = TRUE)
```

# DATA CLEANING / IMPUTATION

## Packages

```{r}
library(dplyr)
```

## Data Cleaning


```{r}
strokes <- x
strokes$EMSvsCar <- factor(strokes$EMSvsCar)

```

```{r}
strokes |> 
  group_by(hadTPA, tpaComplic) |>
  count()

```


```{r}

strokes <- strokes %>%
  mutate(TPA_group = case_when(
    hadTPA == FALSE ~ "NoTPA",
    hadTPA == TRUE & tpaComplic == FALSE ~ "TPA_NoComp",
    hadTPA == TRUE & tpaComplic == TRUE  ~ "TPA_Comp"
  ))

# Optional: make it a factor with ordered levels
strokes <- strokes %>%
  mutate(TPA_group = factor(TPA_group, levels = c("NoTPA", "TPA_NoComp", "TPA_Comp")))

# Check result
table(strokes$TPA_group)

strokes <- strokes |>
  select(-hadTPA) |>
  select(-tpaComplic)

```
There is some correlation with hadTP and tpaComplication, so we made a new variable and removed the other two.


## Missingness

### First impute age, then EMS vs Car,  then Notify

I chose this order because of the dependency thing (unless I misunderstood that). 


PreHospNotify cannot be imputed without knowing EMSvsCar first. --> this is because when EMSvsCar = 1, PreHospNotify has be No.

See
```{r}
strokes |> group_by(strokes$EMSvsCar, PreHospNotify) |> count()
```


We need to maintain the constraint thought that if it's car, there won't be notify. --> I asked and because there's not a forced rule for when EMS vs Car equals 1, i.e. EMS could be PreHospNotify = YES or NO when it's 1. It recommended resolving using post-processing. 



```{r}
library(mice)

# Select relevant variables or full dataset
#data <- strokes |>
  #select(-siteID)


strokes$siteID <-factor(strokes$siteID)
data <- strokes

# STEP 1: Specify imputation methods
# "" means: do NOT impute the variable
method <- make.method(data)

method["Age"] <- "pmm"
method["EMSvsCar"] <- "logreg"         # assuming it's binary
method["PreHospNotify"] <- "logreg"    # assuming it's binary

# Make sure NO OTHER variables are imputed
for (v in names(method)) {
  if (!v %in% c("Age", "EMSvsCar", "PreHospNotify")) {
    method[v] <- ""
  }
}

# STEP 2: Build predictor matrix
pred <- make.predictorMatrix(data)

# Remove self-prediction
pred["Age", "Age"] <- 0
pred["EMSvsCar", "EMSvsCar"] <- 0
pred["PreHospNotify", "PreHospNotify"] <- 0

# (OPTIONAL) If you want all variables to predict the three variables,
# keep predictor matrix as is.
# Or customize:
# pred["EMSvsCar", ] <- 0
# pred["EMSvsCar", c("Age")] <- 1

# STEP 3: Set the order of imputation
visitSequence <- c("Age", "EMSvsCar", "PreHospNotify")

# STEP 4: Run MICE
imp <- mice(
  data,
  m = 20,
  method = method,
  predictorMatrix = pred,
  visitSequence = visitSequence,
  maxit = 20,
  print = FALSE
)

```
### my post-processing

holds that all cases where EMS vs Car = 0, there won't be a prehospital notify  

```{r}
completed_list <- mice::complete(imp, action = "all")

# Define the categories exactly as they appear in your data
fix_rule <- function(df) {
  df$PreHospNotify[df$EMSvsCar == 0] <- "No"
  return(df)
}

completed_fixed <- lapply(completed_list, fix_rule)


```


### Rule out MNAR

Need to validate we can make the MAR assumption. These are diagnostics. 



```{r eval=FALSE}
flip_some <- function(x, prop = 0.1) {
  # x: factor with 2 levels
  levels_x <- levels(x)
  if(length(levels_x) < 2) return(x)  # cannot flip
  idx <- sample(which(x == levels_x[1]), size = floor(prop*sum(x==levels_x[1])))
  x[idx] <- levels_x[2]
  return(x)
}

delta_age <- c(-1, 0, 1)  # small numeric shifts
delta_ems <- c(-1, 0, 1)  # only flip some cases
delta_pre <- c("flip_some", "none")

sensitivity_results <- list()

for(a in delta_age){
  for(e in delta_ems){
    for(pn in delta_pre){
      
      adjusted_dfs <- lapply(completed_fixed, function(df){
        df_new <- df
        
        # AGE adjustment
        df_new$Age <- df_new$Age + a
        
        # EMSvsCar adjustment (flip some)
        if(e != 0){
          df_new$EMSvsCar <- flip_some(df_new$EMSvsCar, prop = 0.1)
        }
        
        # PreHospNotify adjustment (flip some)
        if(pn == "flip_some"){
          df_new$PreHospNotify <- flip_some(df_new$PreHospNotify, prop = 0.1)
        }
        
        df_new
      })
      
      # Fit models and pool
      model_list <- lapply(adjusted_dfs, function(df){
        glm(homeOrRehab ~ Age + EMSvsCar + PreHospNotify,
            data = df, family = binomial)
      })
      
      pooled <- pool(model_list)
      pooled_summary <- summary(pooled)
      
      scenario_name <- paste0("Age_", a, "_EMS_", e, "_Pre_", pn)
      sensitivity_results[[scenario_name]] <- pooled_summary
    }
  }
}

```


```{r,eval=FALSE}
model_results <- lapply(sensitivity_age, function(s) {
  with(mice::as.mids(s$data), glm(StrokeOutcome ~ Age + EMSvsCar + PreHospNotify, family=binomial))
})

library(dplyr)

# Extract key variables (Age, EMSvsCar, PreHospNotify)
extract_var <- function(var_name){
  lapply(names(sensitivity_results), function(s){
    res <- sensitivity_results[[s]]
    
    # Skip if not a data frame
    if(!is.data.frame(res)) return(NULL)
    
    # Filter variable row
    df <- res %>%
      filter(term == var_name) %>%
      select(term, estimate, std.error, p.value) %>%
      mutate(scenario = s)
    
    df
  }) %>% bind_rows()
}

# Get estimates for each variable
age_results <- extract_var("Age")
ems_results <- extract_var("EMSvsCar")
pre_results <- extract_var("PreHospNotify")

```

```{r}
library(ggplot2)

# Combine all variables into one data frame for plotting

if (FALSE)
{
sensitivity_plot_data <- bind_rows(
  age_results %>% mutate(variable = "Age"),
  ems_results %>% mutate(variable = "EMSvsCar"),
  pre_results %>% mutate(variable = "PreHospNotify")
)

# Optional: create a simpler scenario label
sensitivity_plot_data <- sensitivity_plot_data %>%
  mutate(scenario_short = gsub("Age_|_EMS_|_Pre_", "", scenario))

# Plot
ggplot(sensitivity_plot_data, aes(x = scenario, y = estimate, color = variable)) +
  geom_point(position = position_dodge(width = 0.5)) +
  geom_errorbar(aes(ymin = estimate - 1.96*std.error, ymax = estimate + 1.96*std.error),
                width = 0.2, position = position_dodge(width = 0.5)) +
  facet_wrap(~ variable, scales = "free_y") +
  labs(
    title = "Sensitivity Analysis: Effect Estimates Across Scenarios",
    x = "Scenario",
    y = "Estimated Coefficient (log-odds)",
    color = "Variable"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
}

```



# EDA (POST IMPUTATION)

First is just checking the distributions pre and post imputation (they should be approximately the same):

```{r}
# Combining all completed datasets into a long dataframe
post_imp_long <- bind_rows(
  lapply(seq_along(completed_fixed), function(i) {
    completed_fixed[[i]] |> mutate(.imp = i)
  })
)

# Age
orig <- x |> mutate(.imp = "Original")

post_imp_long2 <- post_imp_long |> 
  mutate(.imp = as.character(.imp))

age_compare <- bind_rows(
  orig |> select(Age, .imp),
  post_imp_long2 |> select(Age, .imp)
)

ggplot(age_compare, aes(x = Age, fill = factor(.imp))) +
  geom_density(alpha = 0.2) +
  labs(
    title = "Age Distribution: Original vs. Imputed Datasets",
    x = "Age",
    y = "Density",
    fill = "Dataset"
  ) +
  theme_minimal() +
  facet_wrap(~factor(.imp))
```

```{r,eval=FALSE}
# EMSvsCar, PreHospNotify
orig_summary <- x |>
  summarize(
    EMSvsCar = mean(EMSvsCar == 1, na.rm = TRUE),
    PreHospNotify = mean(PreHospNotify == "Yes", na.rm = TRUE)
  ) |>
  mutate(.imp = "Original") |>
  pivot_longer(
    cols = c("EMSvsCar", "PreHospNotify"),
    names_to = "variable",
    values_to = "prop_yes"
  )

imp_summary <- post_imp_long |>
  mutate(
    .imp = as.character(.imp),
    EMSvsCar = as.numeric(as.character(EMSvsCar)),
    PreHospNotify = as.character(PreHospNotify)
  ) |>
  group_by(.imp) |>
  summarize(
    EMSvsCar = mean(EMSvsCar == 1, na.rm = TRUE),
    PreHospNotify = mean(PreHospNotify == "Yes", na.rm = TRUE)
  ) |>
  pivot_longer(
    cols = c("EMSvsCar", "PreHospNotify"),
    names_to = "variable",
    values_to = "prop_yes"
  )

binary_summary_all <- binary_summary_all |>
  mutate(
    .imp = factor(.imp, levels = c("Original", as.character(1:20)))
  )

ggplot(binary_summary_all, aes(x = .imp, y = prop_yes, fill = (.imp == "Original"))) +
  geom_col() +
  facet_wrap(~ variable, nrow = 1) +
  scale_fill_manual(values = c("grey70", "tomato"), guide = "none") +
  labs(
    title = "Proportion of Binary Variables: Original vs. Imputed Datasets",
    x = "Dataset",
    y = "Proportion 'Yes'"
  ) +
  coord_cartesian(ylim = c(0, 1)) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

Now onto EDA for association:

```{r, fig.width=18, fig.height=10,eval=FALSE}
# just doing eda with 1st bc distributions roughly the same - obviously we would want to use all for prediction, but more lax in this case
assoc_df <- eda_df |>
  select(
    Disposition,
    AgeGroup,
    Gender,
    Race2,
    ArrivalMode,
    PreHospitalNotification,
    Thrombectomy,
    TPAComplication,
    ThrombectomyComplication,
    StudyQuarter
  ) |>
  pivot_longer(
    cols = -Disposition,
    names_to = "Variable",
    values_to = "Level"
  ) |>
  group_by(Variable, Level) |>
  summarize(
    n = n(),
    prop_favorable = mean(Disposition == "Favorable Discharge"),
    se = sqrt(prop_favorable * (1 - prop_favorable) / n),
    .groups = "drop"
  ) |>
  mutate(
    Variable = recode(
      Variable,
      AgeGroup = "Age Group",
      Gender = "Gender",
      Race2 = "Race",
      ArrivalMode = "Arrival Mode",
      PreHospitalNotification = "Pre-Hospital Notification",
      Thrombectomy = "Thrombectomy",
      TPAComplication = "TPA Complication",
      ThrombectomyComplication = "Thrombectomy Complication",
      StudyQuarter = "Study Quarter"
    )
  )

ggplot(assoc_df, aes(x = Level, y = prop_favorable)) +
  geom_col(fill = "#4472C4") +
  geom_errorbar(
    aes(
      ymin = prop_favorable - 1.96 * se,
      ymax = prop_favorable + 1.96 * se
    ),
    width = 0.2
  ) +
  facet_wrap(~ Variable, scales = "free_x", nrow = 2) +
  scale_y_continuous(labels = scales::percent_format(), limits = c(0, 1)) +
  labs(
    title = "Association Between Predictors and Favorable Discharge",
    x = "",
    y = "Percent Favorable Discharge"
  ) +
  theme_minimal(base_size = 15) +
  theme(
    strip.text = element_text(face = "bold", size = 16),
    axis.text.x = element_text(angle = 45, hjust = 1, size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 20, face = "bold")
  )
```





# MODIFIED IMPUTATION

```{r}
library(rjags)

# --- Step 1: Preprocess data ---
strokes$Age[strokes$Age == ""] <- NA
strokes$EMSvsCar[strokes$EMSvsCar == ""] <- NA
strokes$PreHospNotify[strokes$PreHospNotify == ""] <- NA
strokes$Race2[strokes$Race2 == "Missing"] <- NA
strokes$Race2 <- factor(strokes$Race2)
strokes <- strokes |> 
  mutate(Time2 = case_when(Time2 == "Y1Q1" | Time2 == "Y1Q1" ~ 1,
                           Time2 == "Y2Q3" | Time2 == "Y2Q4" ~ 3,
                           TRUE ~ 2))
# Create TransportNotify variable
strokes$TransportNotify <- with(
  strokes,
  ifelse(EMSvsCar == 0, 1,
         ifelse(PreHospNotify == 0, 2, 3))
)
strokes$TransportNotify <- as.numeric(strokes$TransportNotify)

# Convert site to numeric
strokes$siteID <- as.numeric(factor(strokes$siteID))

# --- Step 2: Select covariates automatically ---
outcomes <- c("Age", "TransportNotify", "Race2", "siteID")
covariate_names <- grep(paste(outcomes, collapse="|"), 
                        names(strokes), 
                        invert = TRUE, 
                        value = TRUE)

# Convert factors/logicals to numeric and handle NAs
X <- strokes[, covariate_names]
X <- data.frame(lapply(X, function(x) {
  if(is.factor(x) | is.logical(x)) x <- as.numeric(x)
  x[is.na(x)] <- 0  # temporary placeholder
  return(x)
}))
X <- as.matrix(X)
NCOV <- ncol(X)

# --- Step 3: Prepare data for JAGS ---
jags_data <- list(
  N = nrow(strokes),
  age = strokes$Age,
  tr = strokes$TransportNotify,
  race = as.numeric(strokes$Race2),
  site = strokes$siteID,
  nsite = length(unique(strokes$siteID)),
  K_tr = 3,
  K_race = length(levels(strokes$Race2)),
  NCOV = NCOV,
  X = X,
  alpha = rep(0.5, length(levels(strokes$Race2))),
  Y = as.integer(strokes$homeOrRehab)
)

# --- Step 4: Write JAGS model ---
model_string <- "
model {

  #### AGE MODEL (regression + site random effect) ####
  for (i in 1:N) {
    age[i] ~ dnorm(mu_age[i], tau_age)
    mu_age[i] <- beta0 + inprod(beta[], X[i,]) + b_site[site[i]]
  }
  tau_age ~ dgamma(0.01,0.01)
  sigma_age <- 1/sqrt(tau_age)

  for (s in 1:nsite) {
    b_site[s] ~ dnorm(0, tau_b)
  }
  tau_b ~ dgamma(0.01,0.01)
  sigma_b <- 1/sqrt(tau_b)

  for (j in 1:NCOV) {
    beta[j] ~ dnorm(0,0.001)
  }
  beta0 ~ dnorm(0,0.001)

  #### TRANSPORT-NOTIFY MODEL (multinomial logistic regression + site random effects) ####
  for (i in 1:N) {
    tr[i] ~ dcat(pi_tr[i,1:K_tr])
    for (k in 1:K_tr) {
      logit(pi_tr[i,k]) <- alpha_tr[k] + inprod(gamma[k,], X[i,]) + u_site[site[i],k]
    }
  }

  for (s in 1:nsite) {
    for (k in 1:K_tr) {
      u_site[s,k] ~ dnorm(0, tau_u)
    }
  }
  tau_u ~ dgamma(0.01,0.01)

  for (k in 1:K_tr) {
    for (j in 1:NCOV) {
      gamma[k,j] ~ dnorm(0,0.001)
    }
    alpha_tr[k] ~ dnorm(0,0.001)
  }

  #### RACE MODEL (site-only) ####
  for (i in 1:N) {
    race[i] ~ dcat(pi_race[site[i],1:K_race])
  }

  for (s in 1:nsite) {
    pi_race[s,1:K_race] ~ ddirch(alpha[1:K_race])
  }
}
"

writeLines(model_string, con = "jags_impute_model.txt")

# --- Step 5: Set initial values ---
inits_list <- list(
  list(beta0=50, beta=rep(0,NCOV), tau_age=1, tau_b=1,
       u_site=matrix(0,nrow=jags_data$nsite,ncol=jags_data$K_tr),
       gamma=matrix(0,jags_data$K_tr,NCOV), alpha_tr=rep(0,jags_data$K_tr),
       ),
  list(beta0=40, beta=rep(0,NCOV), tau_age=1, tau_b=50,
       u_site=matrix(0,nrow=jags_data$nsite,ncol=jags_data$K_tr),
       gamma=matrix(0,jags_data$K_tr,NCOV), alpha_tr=rep(0,jags_data$K_tr)),
  list(beta0=60, beta=rep(0,NCOV), tau_age=1, tau_b=15,
       u_site=matrix(0,nrow=jags_data$nsite,ncol=jags_data$K_tr),
       gamma=matrix(0,jags_data$K_tr,NCOV), alpha_tr=rep(0,jags_data$K_tr))
)

# --- Step 6: Parameters to monitor ---
params <- c("age", "mu_age", "tr", "race", "beta0", "beta", "tau_age", "b_site", "tau_b", "gamma", "alpha_tr", "u_site", "pi_race")


# --- Step 7: Run JAGS ---
jmod <- jags.model("jags_impute_model.txt", data=jags_data, inits=inits_list,
                   n.chains=3, n.adapt=1000)
update(jmod, 2000)
samples <- coda.samples(jmod, variable.names=params, n.iter=20000)

# --- Step 8: Inspect samples ---
samples

samp <- saveRDS(samples, "samples")

```
```{r}

samples <- readRDS("samples")

library(coda)

# --- Extract hyperparameters from the posterior ---
# Assuming 'samples' is a coda mcmc.list
samples_hyper <- samples[, c("beta0", "tau_age", "tau_b")]

# --- Gelman-Rubin diagnostic ---
gelman.diag(samples_hyper)

# --- Traceplots ---
traceplot(samples[, c("beta0", "tau_age", "tau_b")])

# --- Effective sample size ---
effectiveSize(samples[, c("beta0", "tau_age", "tau_b")])


```
```{r}
library(dplyr)
library(coda)

# ============================================================
# STEP 0 — PREPARE DATA + POSTERIOR MATRIX
# ============================================================

post_mat <- as.matrix(samples)  # convert coda object to matrix
N <- nrow(strokes)

# Identify missing data
missing_age  <- which(is.na(strokes$Age))
missing_tr   <- which(is.na(strokes$TransportNotify))

# ---- Prepare Race2: convert to numeric codes for safe imputation ----
race_levels <- levels(strokes$Race2)
strokes$Race2_num <- as.numeric(strokes$Race2)
missing_race <- which(is.na(strokes$Race2_num))
K_race <- length(race_levels)

# ---- Site indexing ----
sites  <- unique(strokes$siteID)
Nsites <- length(sites)
site_index <- match(strokes$siteID, sites)

# ---- Posterior parameter name groups ----
b_names  <- grep("^b_site\\[",  colnames(post_mat), value=TRUE)
u_names  <- grep("^u_site\\[",  colnames(post_mat), value=TRUE)
pi_names <- grep("^pi_race\\[", colnames(post_mat), value=TRUE)

NCOV <- ncol(X)
K_tr <- 3  # transport categories

# Number of imputed datasets
m <- 20
imputed_datasets <- vector("list", m)


# ============================================================
# STEP 1 — IMPUTATION LOOP
# ============================================================

set.seed(123)

for (j in 1:m) {

  iter <- sample(seq_len(nrow(post_mat)), 1)
  post <- post_mat[iter, ]

  imputed_data <- strokes


  # ============================================================
  # 1. IMPUTE AGE (Normal regression w/ site random effects)
  # ============================================================

  mu_age <- rep(post["beta0"], N)

  # fixed effects
  beta_idx <- paste0("beta[", 1:NCOV, "]")
  mu_age <- mu_age + as.numeric(X %*% post[beta_idx])

  # site random effects
  b_vals <- post[b_names]
  if (length(b_vals) != Nsites)
      stop("Dimension mismatch in b_site")

  mu_age <- mu_age + b_vals[site_index]

  # draw age imputations
  tau_age <- post["tau_age"]
  imputed_data$Age[missing_age] <- rnorm(
    length(missing_age),
    mean = mu_age[missing_age],
    sd   = 1/sqrt(tau_age)
  )


  # ============================================================
  # 2. IMPUTE TRANSPORT NOTIFY (Multinomial logistic)
  # ============================================================

  # alpha_tr[k]
  alpha_tr <- post[paste0("alpha_tr[", 1:K_tr, "]")]

  # gamma[k,]
  gamma_mat <- matrix(NA, nrow=K_tr, ncol=NCOV)
  for (k in 1:K_tr) {
    gamma_mat[k, ] <- post[grep(
      paste0("^gamma\\[", k, ","),
      names(post)
    )]
  }

  # u_site[site,k] matrix
  u_mat <- matrix(post[u_names], nrow=Nsites, ncol=K_tr, byrow=TRUE)

  # logits (N × K_tr)
  logits <- matrix(0, nrow=N, ncol=K_tr)
  for (k in 1:K_tr) {
    logits[, k] <- alpha_tr[k] + X %*% gamma_mat[k, ] + u_mat[site_index, k]
  }

  # stable softmax
  logits_c <- logits - apply(logits, 1, max)
  exp_logits <- exp(logits_c)
  tr_probs <- exp_logits / rowSums(exp_logits)

  # impute transport notify
  for (i in missing_tr) {
    imputed_data$TransportNotify[i] <-
      sample(1:K_tr, 1, prob = tr_probs[i, ])
  }


  # ============================================================
  # 3. IMPUTE RACE2 (site-specific categorical)
  # ============================================================

  # reshape pi_race to (site × race)
  pi_mat <- matrix(
    post[pi_names],
    nrow = Nsites,
    ncol = K_race,
    byrow = TRUE
  )

  # safety: no negative or NA probabilities
  if (any(is.na(pi_mat)))
      stop("NA in posterior pi_race matrix.")
  pi_mat <- abs(pi_mat)
  pi_mat <- pi_mat / rowSums(pi_mat)

  # impute numeric race category
  for (i in missing_race) {
    s_row <- site_index[i]
    probs <- pi_mat[s_row, ]
    imputed_data$Race2_num[i] <- sample(seq_len(K_race), 1, prob = probs)
  }


  # store dataset
  imputed_datasets[[j]] <- imputed_data
}


# ============================================================
# STEP 2 — CONVERT RACE BACK TO FACTOR IN ALL DATASETS
# ============================================================

for (j in 1:m) {
  imputed_datasets[[j]]$Race2 <- factor(
    race_levels[ imputed_datasets[[j]]$Race2_num ],
    levels = race_levels
  )
}

savedRDS(imputed_datasets, "imputed_data")
```

`




```{r}
library(ggplot2)
library(coda)
library(dplyr)
library(tidyr)

# --- Step 1: Convert posterior to matrix ---
posterior_samples <- as.matrix(samples)

# --- Step 2: Exclude imputed variables ---
exclude_params <- c("^age", "^tr", "^race")
param_names <- colnames(posterior_samples)
param_names <- param_names[!grepl(paste(exclude_params, collapse="|"), param_names)]
# After excluding imputed variables, choose which parameters to plot
relevant_params <- c("beta0", "beta_age", "beta_race", "tau_age", "tau_b")

param_names <- param_names[param_names %in% relevant_params]


# --- Step 3: Prepare a long-format data frame for posterior ---
posterior_df <- as.data.frame(posterior_samples[, param_names])
posterior_long <- posterior_df %>%
  pivot_longer(everything(), names_to = "parameter", values_to = "posterior")

# --- Step 4: Compute prior densities ---
prior_list <- lapply(param_names, function(p) {
  
  # default prior values from your JAGS model
  if(grepl("^beta", p) | grepl("^gamma", p)) {
    mean0 <- 0
    sd0 <- sqrt(1/0.001)
  } else if(grepl("^beta0", p) | grepl("^alpha_tr", p)) {
    mean0 <- 0
    sd0 <- sqrt(1/0.001)
  } else if(grepl("^tau", p)) {
    # tau ~ dgamma(0.01,0.01)
    # approximate prior density using rgamma
    x_seq <- seq(0, max(posterior_samples[,p])*2, length.out = 1000)
    density_vals <- dgamma(x_seq, shape = 0.01, rate = 0.01)
    return(data.frame(x=x_seq, density=density_vals, parameter=p, type="Prior"))
  } else if(grepl("^sigma", p)) {
    # transform tau to sigma
    x_seq <- seq(0, max(posterior_samples[,p])*2, length.out = 1000)
    density_vals <- dgamma(1/(x_seq^2), shape=0.01, rate=0.01) * 2/(x_seq^3)
    return(data.frame(x=x_seq, density=density_vals, parameter=p, type="Prior"))
  } else {
    # default fallback prior
    mean0 <- 0
    sd0 <- sqrt(1/0.001)
  }
  
  x_seq <- seq(min(posterior_samples[,p]), max(posterior_samples[,p]), length.out=1000)
  density_vals <- dnorm(x_seq, mean=mean0, sd=sd0)
  data.frame(x=x_seq, density=density_vals, parameter=p, type="Prior")
})

prior_df <- do.call(rbind, prior_list)

# --- Step 5: Combine posterior as density estimates ---
posterior_density <- posterior_long %>%
  group_by(parameter) %>%
  summarise(posterior_density = list(density(posterior)$y),
            posterior_x = list(density(posterior)$x)) %>%
  unnest(c(posterior_x, posterior_density)) %>%
  mutate(type="Posterior")

# --- Step 6: Combine prior and posterior ---
plot_df <- bind_rows(
  prior_df %>% rename(x=x, density=density),
  posterior_density %>% rename(x=posterior_x, density=posterior_density)
)

# --- Step 7: Plot ---
ggplot(plot_df, aes(x=x, y=density, color=type)) +
  geom_line(size=1) +
  facet_wrap(~parameter, scales="free") +
  scale_color_manual(values=c("Prior"="blue","Posterior"="red")) +
  labs(title="Prior vs Posterior for All Parameters (excluding imputed variables)",
       x="Parameter value", y="Density") +
  theme_minimal() +
  theme(legend.position="top")

```




```{r}
mu_cols <- grep("mu_age", colnames(samples[[1]]))
mu_draws <- as.matrix(samples)[, mu_cols]
mu_hat <- colMeans(mu_draws)
resid <- strokes$Age - mu_hat

# Residual vs fitted
plot(mu_hat, resid,
     xlab="Fitted Age", ylab="Residuals",
     main="Residuals vs Fitted")
abline(h=0, col="red")

# Check for non-constant variance
plot(mu_hat, abs(resid),
     xlab="Fitted Age", ylab="|Residual|",
     main="Heteroskedasticity Check")

```


# FREQUENTIST ANALYSIS

```{r}
library(pROC)
library(lme4)
results = NULL
AUCs = NULL
test <- readRDS("imputed_data")
for (i in 1:20){
  data <- test[[i]]
  data$homeOrRehab <- if_else(data$homeOrRehab,1,0)
  modelFit <- glm(factor(homeOrRehab) ~ ., data = data, family = "binomial")
  AUCs <- c(AUCs,auc(data$homeOrRehab,predict(modelFit,data)))
  results <- c(results, list(summary(modelFit)))
}
arm::binnedplot(fitted(modelFit),residuals(modelFit))
plot.roc(data$homeOrRehab,predict(modelFit,data))
results[[1]]$coefficients |> 
  as.data.frame() |> 
  select(-`z value`) |> 
  kableExtra::kable()
data.frame(iter = seq(1,20), AUC = AUCs) |> 
  kableExtra::kable()
```

# BAYESIAN ANALYSIS
{{< pagebreak >}}
```{r}
dataImputed <- readRDS("imputed_data")
library(rstan)
alpha <- beta <- tau <- r_hat <- n_eff <- Preds <- NULL
n_chains <- 2
for (i in 1:20){
data <- dataImputed[[i]]
data <- data |> 
  mutate(Time2 = case_when(Time2 == "Y1Q1" | Time2 == "Y1Q1" ~ 1,
                           Time2 == "Y2Q3" | Time2 == "Y2Q4" ~ 3,
                           TRUE ~ 2),
         Time2 = as.factor(Time2)) |> 
  select(-Race2_num,-EMSvsCar,-PreHospNotify)
Y <- as.integer(data$homeOrRehab)
X <- model.matrix(~.,data =data[2:10])[,-1]
X <- X[,-9]
Ids <- as.numeric(data$siteID)
n <- length(unique(Ids))
N <- nrow(X)
p <- ncol(X)
stan_data <- list(
  Y = Y,
  X = X,
  Ids = Ids,
  n = n,
  N = N,
  p = p
)
compiled_model <- stan_model(file = "logRegRE.stan")
options(mc.cores = 4)
fit_mi <- sampling(compiled_model, data = stan_data)

###Save convergence diagnostics from each imputed dataset
  r_hat <- cbind(r_hat, summary(fit_mi)$summary[, "Rhat"])
  n_eff <- cbind(n_eff, summary(fit_mi)$summary[, "n_eff"])
  pars <- rstan::extract(fit_mi, pars = c("alpha", "beta", "tau"))
  Y_pred <- rstan::extract(fit_mi, pars = "Y_pred")$Y_pred
  ### Save the parameters from each imputed dataset
  n_sims_chain <- length(pars$alpha) / n_chains
  alpha <- rbind(alpha, cbind(i, rep(1:n_chains, each = n_sims_chain), pars$alpha))
  beta <- rbind(beta, cbind(i, rep(1:n_chains, each = n_sims_chain), pars$beta))
  tau <- rbind(tau, cbind(i, rep(1:n_chains, each = n_sims_chain), pars$tau))
  Preds <-  rbind(Preds, cbind(i, rep(1:n_chains, each = n_sims_chain), Y_pred))
}  
saveRDS(alpha,"alphas.RDS")
saveRDS(beta,"betas.RDS")
saveRDS(tau,"taus.RDS")
saveRDS(Preds,"Y_preds.RDS")
coda::effectiveSize(beta)
library(bayesplot)
Y_pred <- rstan::extract(fit, pars = "Y_pred")$Y_pred
ppc_bars(Y, Y_pred[1:100, ])
ppc_bars_grouped(Y, Y_pred[1:100, ],data$Time2)
traceplot(fit, pars = c("alpha","beta"))
mcmc_acf(fit, regex_pars = c("alpha","beta"))
```



```{r}
Y <- as.integer(strokes$homeOrRehab)
#strokes <- strokes |> 
#  select(-EMSvsCar,-PreHospNotify) 
strokes$Age[is.na(strokes$Age)] <- -99
strokes$Race2 <- as.character(strokes$Race2)
strokes$Race2[is.na(strokes$Race2)] <- "XMissing"
strokes$Race2 <- as.factor(strokes$Race2)
strokes$TransportNotify[is.na(strokes$TransportNotify)] <- -99
X <- model.matrix(~.,data =strokes[2:10])[,-1]
X <- X[,-14]
Ids <- as.numeric(data$siteID)
n <- length(unique(Ids))
N <- nrow(X)
p <- ncol(X)
stan_data <- list(
  Y = Y,
  X = X,
  Ids = Ids,
  n = n,
  N = N,
  p = p
)
```

